{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a89bca-8767-4e70-b99b-9a6a4fa15e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47bd92c0-01c9-4245-84b1-b08b0973c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq sentence-transformers chromadb scikit-build numpy opencv-python unstructured-inference langchain langchain-community langchain-core unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318f2f76-8aaf-48f7-af55-3c70cb4ef058",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq \"gradio==3.50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6bf156c-f34d-4d73-98c5-952d3150170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the warnings in the libraries used can get old, do not show them\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21a7b8ca-ea52-4f28-8f95-312eb34b21d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-05 11:51:45--  https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14\n",
      "Resolving access.redhat.com (access.redhat.com)... 23.216.132.69, 23.216.132.70, 2600:141b:e800:1d::17d8:848d, ...\n",
      "Connecting to access.redhat.com (access.redhat.com)|23.216.132.69|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘index.html’\n",
      "\n",
      "index.html              [ <=>                ] 131.28K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-02-05 11:51:46 (922 KB/s) - ‘index.html’ saved [134431]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O index.html \"https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7189c398-ea2f-416e-b0f4-6fbab96dd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open(\"index.html\", \"r\") as f:\n",
    "    html = f.read()\n",
    "\n",
    "urls = []\n",
    "\n",
    "for x in html.splitlines():\n",
    "    if \"Single-page HTML\" in x:\n",
    "        m = re.match(\".*href=\\\"([^\\\"]*)\\\".*\", x)\n",
    "        urls.append(f\"https://access.redhat.com{m.groups()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343fb5e1-d6d6-4918-8f37-887f8027a5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f701fc-e519-4401-a92b-03c2304553ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model= pipeline(model=\"google/flan-t5-large\") #'text2text-generation'\n",
    "model.save_pretrained(\"flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fffffdd-0070-4795-ba7a-691c5f016f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=\"flan-t5-large\", task=\"text2text-generation\", model_kwargs={\"temperature\":1e-10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05763643-8de2-46bc-915c-458ea06ca72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03e970ca-72f3-4534-ae8f-c386d97c4f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6313"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552b572d-faff-4db1-a6fd-b1b4226344b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:21,825 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying device=cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:22,982 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying device=cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:24,520 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
      "Trying device=ipu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:25,601 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for ipu devices\n",
      "Trying device=xpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:26,666 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for xpu devices\n",
      "Trying device=mkldnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:27,819 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for mkldnn devices\n",
      "Trying device=opengl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:28,865 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for opengl devices\n",
      "Trying device=opencl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:29,952 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for opencl devices\n",
      "Trying device=ideep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:30,904 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for ideep devices\n",
      "Trying device=hip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:31,808 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for hip devices\n",
      "Trying device=ve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:32,751 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for ve devices\n",
      "Trying device=fpga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:33,830 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for fpga devices\n",
      "Trying device=ort\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:34,995 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for ort devices\n",
      "Trying device=xla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:36,094 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for xla devices\n",
      "Trying device=lazy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:37,441 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not run 'aten::empty.memory_format' with arguments from the 'Lazy' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::empty.memory_format' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, QuantizedMeta, MkldnnCPU, SparseCPU, SparseCUDA, SparseMeta, SparseCsrCPU, SparseCsrCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n",
      "\n",
      "CPU: registered at aten/src/ATen/RegisterCPU.cpp:31188 [kernel]\n",
      "CUDA: registered at aten/src/ATen/RegisterCUDA.cpp:44143 [kernel]\n",
      "Meta: registered at aten/src/ATen/RegisterMeta.cpp:26829 [kernel]\n",
      "QuantizedCPU: registered at aten/src/ATen/RegisterQuantizedCPU.cpp:944 [kernel]\n",
      "QuantizedCUDA: registered at aten/src/ATen/RegisterQuantizedCUDA.cpp:459 [kernel]\n",
      "QuantizedMeta: registered at aten/src/ATen/RegisterQuantizedMeta.cpp:105 [kernel]\n",
      "MkldnnCPU: registered at aten/src/ATen/RegisterMkldnnCPU.cpp:515 [kernel]\n",
      "SparseCPU: registered at aten/src/ATen/RegisterSparseCPU.cpp:1387 [kernel]\n",
      "SparseCUDA: registered at aten/src/ATen/RegisterSparseCUDA.cpp:1573 [kernel]\n",
      "SparseMeta: registered at aten/src/ATen/RegisterSparseMeta.cpp:249 [kernel]\n",
      "SparseCsrCPU: registered at aten/src/ATen/RegisterSparseCsrCPU.cpp:1135 [kernel]\n",
      "SparseCsrCUDA: registered at aten/src/ATen/RegisterSparseCsrCUDA.cpp:1276 [kernel]\n",
      "BackendSelect: registered at aten/src/ATen/RegisterBackendSelect.cpp:742 [kernel]\n",
      "Python: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\n",
      "FuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\n",
      "Functionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:290 [backend fallback]\n",
      "Named: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\n",
      "Conjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\n",
      "Negative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:23 [kernel]\n",
      "ZeroTensor: fallthrough registered at ../aten/src/ATen/ZeroTensorFallback.cpp:90 [kernel]\n",
      "ADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\n",
      "AutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "AutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:18694 [autograd kernel]\n",
      "Tracer: registered at ../torch/csrc/autograd/generated/TraceType_2.cpp:17079 [kernel]\n",
      "AutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:382 [backend fallback]\n",
      "AutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:249 [backend fallback]\n",
      "FuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:710 [backend fallback]\n",
      "FuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\n",
      "Batched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\n",
      "VmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n",
      "FuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\n",
      "PythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\n",
      "FuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\n",
      "PreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\n",
      "PythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n",
      "\n",
      "Trying device=vulkan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:38,570 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for vulkan devices\n",
      "Trying device=mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:40,289 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for mps devices\n",
      "Trying device=meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:41,396 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying device=hpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:42,584 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for hpu devices\n",
      "Trying device=mtia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:54:43,696 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is not linked with support for mtia devices\n",
      "Trying device=privateuseone\n",
      "PyTorch is not linked with support for privateuseone devices\n",
      "Working devices=['cpu', 'meta']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "working_devices=[]\n",
    "\n",
    "for device in \"cpu\", \"cuda\", \"ipu\", \"xpu\", \"mkldnn\", \"opengl\", \"opencl\", \"ideep\", \"hip\", \"ve\", \"fpga\", \"ort\", \"xla\", \"lazy\", \"vulkan\", \"mps\", \"meta\", \"hpu\", \"mtia\", \"privateuseone\":\n",
    "    model_kwargs = {'device': device}\n",
    "    print(f\"Trying device={device}\")\n",
    "    try:\n",
    "        hf = HuggingFaceEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs=model_kwargs,\n",
    "            encode_kwargs=encode_kwargs\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    working_devices.append(device)\n",
    "print(f\"Working devices={working_devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec50127-ca5e-4c72-97ea-ab6062db6b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 11:56:04,017 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "# https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.huggingface.HuggingFaceEmbeddings.html\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import torch\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_kwargs = {'device': device}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a68d83d-16c6-40d6-a4e1-2bb87d73731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ed16f363434305b7454706a0528531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 14:40:37,695 - faiss.loader - INFO - Loading faiss with AVX2 support.\n",
      "2024-02-05 14:40:37,747 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 59min 57s, sys: 35min 51s, total: 3h 35min 48s\n",
      "Wall time: 55min 12s\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "%time vectorestore = FAISS.from_documents(pages, hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c8fea9d-a1b3-4822-90d4-eb7e30aa7b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.3 ms, sys: 29.1 ms, total: 60.4 ms\n",
      "Wall time: 60.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time vectorestore.save_local(\"ocp-llm-rag-vectorstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93f77a-3ab2-4a20-8c9d-7022af81364d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
